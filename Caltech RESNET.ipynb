{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Caltech RESNET.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "shS0VnN4J9WL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1RFkvJeKAdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3907e9a0-d881-496d-9e73-7cfcfa9cfc95"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import ConcatDataset\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGHc90zFKGwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c864ba5a-896c-4441-d92d-f92bea13065e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nw49dV_KMyA",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9GkoptWKN6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "7987200b-cb5b-4965-d37e-3fbc683ca9e1"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.init import normal, constant\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512, 256)\n",
        "normal(model.fc.weight, 0.0, 0.01)\n",
        "constant(model.fc.bias, 0.0)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 46827520/46827520 [00:01<00:00, 25242979.00it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yulmr0HBKO2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b7ea02f8-a83a-4a1e-84ea-aac78a3b15ff"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=256, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhUzWi1GKXsH",
        "colab_type": "text"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFiS7qBzKTWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhDHhtNhKsSE",
        "colab_type": "text"
      },
      "source": [
        "# Image Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9OSe3TgKcpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "def accimage_loader(path):\n",
        "    import accimage\n",
        "    try:\n",
        "        return accimage.Image(path)\n",
        "    except IOError:\n",
        "        # Potentially a decoding problem, fall back to PIL.Image\n",
        "        return pil_loader(path)\n",
        "\n",
        "\n",
        "def default_loader(path):\n",
        "    from torchvision import get_image_backend\n",
        "    if get_image_backend() == 'accimage':\n",
        "        return accimage_loader(path)\n",
        "    else:\n",
        "        return pil_loader(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U5J9wsqK0AI",
        "colab_type": "text"
      },
      "source": [
        "# Custom dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p4qXdf6KuVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import os.path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "def makeDataset(dir):\n",
        "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    images = []\n",
        "    for target in sorted(class_to_idx.keys()):\n",
        "        d = os.path.join(dir, target)\n",
        "        if not os.path.isdir(d):\n",
        "            continue\n",
        "        for root, _, fnames in sorted(os.walk(d)):\n",
        "            for fname in sorted(fnames):\n",
        "                path = os.path.join(root, fname)\n",
        "                item = (path, class_to_idx[target])\n",
        "                images.append(item)\n",
        "\n",
        "    return images\n",
        "  \n",
        "class myDataset(Dataset):\n",
        "  \n",
        "  def __init__(self, root_dir, loader= default_loader, transform=None):\n",
        "    super(myDataset, self).__init__()\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "    self.loader = loader\n",
        "    samples = makeDataset(root_dir)\n",
        "    self.samples = samples\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.samples)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    x,y = self.samples[index]\n",
        "    sample = self.loader(x)\n",
        "    if self.transform is not None:\n",
        "       sample = self.transform(sample)\n",
        "\n",
        "    return sample, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-cL-s8eK-5e",
        "colab_type": "text"
      },
      "source": [
        "# Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhQ46KCrK3xU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transform2 = transforms.Compose([transforms.RandomHorizontalFlip(p=1), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "import numpy as np\n",
        "from random import sample\n",
        "import random\n",
        "trans11 = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(p=0),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "trans21 = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(p=1),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "trainset1 = myDataset('/content/256_ObjectCategories', transform=trans11)\n",
        "trainset2 = myDataset('/content/256_ObjectCategories', transform=trans21)\n",
        "testset = myDataset('/content/Test/test', transform=trans11)\n",
        "\n",
        "\n",
        "tset = ConcatDataset((trainset1, trainset2))\n",
        "\n",
        "tloader = torch.utils.data.DataLoader(tset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOwnv9OrLPRR",
        "colab_type": "text"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgBq5Ro4LGbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98876b3b-a299-4e25-cfbf-36bf13cf14e8"
      },
      "source": [
        "for epoch in range(1):\n",
        "  running_loss = 0.0\n",
        "  i=0;\n",
        "  for data in tloader:\n",
        "    x,y=data[0].to(device), data[1].to(device)\n",
        "    output=model(x)\n",
        "    loss=criterion(output,y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    if i % 10 == 9:    # print every 47th mini-batch (47*5 total minis)\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "      (epoch + 1, i + 1, running_loss/10))\n",
        "      running_loss = 0.0\n",
        "            \n",
        "    i=i+1\n",
        "\n",
        "    \n",
        "torch.save(model.state_dict(), '/content/gdrive/My Drive/caltech00.pth')\n",
        "print('Finished Training')\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] loss: 1.035\n",
            "[1,    20] loss: 1.046\n",
            "[1,    30] loss: 0.935\n",
            "[1,    40] loss: 0.941\n",
            "[1,    50] loss: 0.956\n",
            "[1,    60] loss: 0.981\n",
            "[1,    70] loss: 0.879\n",
            "[1,    80] loss: 1.071\n",
            "[1,    90] loss: 0.960\n",
            "[1,   100] loss: 0.940\n",
            "[1,   110] loss: 1.057\n",
            "[1,   120] loss: 0.920\n",
            "[1,   130] loss: 0.975\n",
            "[1,   140] loss: 0.887\n",
            "[1,   150] loss: 0.876\n",
            "[1,   160] loss: 0.845\n",
            "[1,   170] loss: 1.019\n",
            "[1,   180] loss: 0.844\n",
            "[1,   190] loss: 0.947\n",
            "[1,   200] loss: 0.872\n",
            "[1,   210] loss: 0.951\n",
            "[1,   220] loss: 0.916\n",
            "[1,   230] loss: 0.888\n",
            "[1,   240] loss: 0.830\n",
            "[1,   250] loss: 0.873\n",
            "[1,   260] loss: 0.852\n",
            "[1,   270] loss: 0.866\n",
            "[1,   280] loss: 0.914\n",
            "[1,   290] loss: 0.881\n",
            "[1,   300] loss: 0.881\n",
            "[1,   310] loss: 0.941\n",
            "[1,   320] loss: 0.888\n",
            "[1,   330] loss: 0.820\n",
            "[1,   340] loss: 0.862\n",
            "[1,   350] loss: 0.891\n",
            "[1,   360] loss: 0.763\n",
            "[1,   370] loss: 0.825\n",
            "[1,   380] loss: 0.945\n",
            "[1,   390] loss: 0.871\n",
            "[1,   400] loss: 0.768\n",
            "[1,   410] loss: 0.867\n",
            "[1,   420] loss: 0.876\n",
            "[1,   430] loss: 0.878\n",
            "[1,   440] loss: 0.856\n",
            "[1,   450] loss: 0.841\n",
            "[1,   460] loss: 0.796\n",
            "[1,   470] loss: 0.728\n",
            "[1,   480] loss: 0.818\n",
            "[1,   490] loss: 0.755\n",
            "[1,   500] loss: 0.798\n",
            "[1,   510] loss: 0.825\n",
            "[1,   520] loss: 0.757\n",
            "[1,   530] loss: 0.880\n",
            "[1,   540] loss: 0.763\n",
            "[1,   550] loss: 0.836\n",
            "[1,   560] loss: 0.754\n",
            "[1,   570] loss: 0.860\n",
            "[1,   580] loss: 0.772\n",
            "[1,   590] loss: 0.821\n",
            "[1,   600] loss: 0.863\n",
            "[1,   610] loss: 0.786\n",
            "[1,   620] loss: 0.784\n",
            "[1,   630] loss: 0.716\n",
            "[1,   640] loss: 0.716\n",
            "[1,   650] loss: 0.723\n",
            "[1,   660] loss: 0.797\n",
            "[1,   670] loss: 0.693\n",
            "[1,   680] loss: 0.702\n",
            "[1,   690] loss: 0.801\n",
            "[1,   700] loss: 0.802\n",
            "[1,   710] loss: 0.741\n",
            "[1,   720] loss: 0.814\n",
            "[1,   730] loss: 0.764\n",
            "[1,   740] loss: 0.731\n",
            "[1,   750] loss: 0.746\n",
            "[1,   760] loss: 0.748\n",
            "[1,   770] loss: 0.741\n",
            "[1,   780] loss: 0.671\n",
            "[1,   790] loss: 0.710\n",
            "[1,   800] loss: 0.679\n",
            "[1,   810] loss: 0.670\n",
            "[1,   820] loss: 0.670\n",
            "[1,   830] loss: 0.612\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g5sA1ShMqmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "bdae8150-c817-497c-ef96-273df11b328e"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "for epoch in range(2):\n",
        "  running_loss = 0.0\n",
        "  i=0;\n",
        "  for data in tloader:\n",
        "    x,y=data[0].to(device), data[1].to(device)\n",
        "    output=model(x)\n",
        "    loss=criterion(output,y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    if i % 46 == 45:    # print every 47th mini-batch (47*5 total minis)\n",
        "      print('[%d, %5d] loss: %.3f' %\n",
        "      (epoch + 1, i + 1, running_loss/46))\n",
        "      running_loss = 0.0\n",
        "            \n",
        "    i=i+1\n",
        "\n",
        "    \n",
        "torch.save(model.state_dict(), '/content/gdrive/My Drive/caltech001.pth')\n",
        "print('Finished Training')\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    46] loss: 0.477\n",
            "[1,    92] loss: 0.402\n",
            "[1,   138] loss: 0.375\n",
            "[1,   184] loss: 0.373\n",
            "[1,   230] loss: 0.354\n",
            "[1,   276] loss: 0.343\n",
            "[1,   322] loss: 0.330\n",
            "[1,   368] loss: 0.317\n",
            "[1,   414] loss: 0.310\n",
            "[1,   460] loss: 0.310\n",
            "[1,   506] loss: 0.307\n",
            "[1,   552] loss: 0.310\n",
            "[1,   598] loss: 0.309\n",
            "[1,   644] loss: 0.285\n",
            "[1,   690] loss: 0.300\n",
            "[1,   736] loss: 0.304\n",
            "[1,   782] loss: 0.292\n",
            "[1,   828] loss: 0.267\n",
            "[2,    46] loss: 0.258\n",
            "[2,    92] loss: 0.232\n",
            "[2,   138] loss: 0.235\n",
            "[2,   184] loss: 0.238\n",
            "[2,   230] loss: 0.256\n",
            "[2,   276] loss: 0.276\n",
            "[2,   322] loss: 0.253\n",
            "[2,   368] loss: 0.244\n",
            "[2,   414] loss: 0.240\n",
            "[2,   460] loss: 0.232\n",
            "[2,   506] loss: 0.237\n",
            "[2,   552] loss: 0.249\n",
            "[2,   598] loss: 0.252\n",
            "[2,   644] loss: 0.243\n",
            "[2,   690] loss: 0.250\n",
            "[2,   736] loss: 0.240\n",
            "[2,   782] loss: 0.263\n",
            "[2,   828] loss: 0.240\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2TYhHWMLkw1",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coCJm4_RLX9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71664d2c-3c7d-444b-d5c7-b5bcf67cd0ef"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in tloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the train images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the train images: 95 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRJcYP9KN44u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c168bd22-a5ca-4185-ba4d-7d01db6bd49f"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 81 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE2k2tHUL4h2",
        "colab_type": "text"
      },
      "source": [
        "# Load and Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69QcwpkiL-kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(torch.load('/content/gdrive/My Drive/caltech10.pth'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu_PAqLhMBYm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), '/content/gdrive/My Drive/caltech32.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m86OK2bcMFJ8",
        "colab_type": "text"
      },
      "source": [
        "# Data Unzip and Splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnbP4j1TMSUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!tar -xvf '/content/gdrive/My Drive/CaltechZipped/256_ObjectCategories.tar'\n",
        "#!unzip '/content/Test'\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "os.remove('/content/256_ObjectCategories/198.spider/RENAME2')\n",
        "#shutil.rmtree('/content/256_ObjectCategories/257.clutter')\n",
        "#shutil.rmtree('/content/Test/test/257.clutter')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO3_ElRBMYQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6f98d62-4ebe-45b0-8d3a-3389ad29293d"
      },
      "source": [
        "import os\n",
        "import os.path\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "myRoot = '/content/256_ObjectCategories'\n",
        "dest = '/content/Test/test/'\n",
        "classes = [d for d in os.listdir(myRoot)]\n",
        "classes.sort()\n",
        "i=0\n",
        "for imgFolder in classes:\n",
        "  src = os.path.join(myRoot, imgFolder)\n",
        "  for image in os.listdir(src):\n",
        "    # for 10% (z from Standard normal distribution curve)\n",
        "    if np.random.randn(1)<-1.285:\n",
        "      i=i+1\n",
        "      if not os.path.exists(dest + imgFolder):\n",
        "        os.mkdir(dest + imgFolder)\n",
        "      shutil.move(src +'/'+ image , dest + imgFolder)\n",
        "      \n",
        "print(i)\n",
        "      \n",
        "    "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7WsnAI8MgJ3",
        "colab_type": "text"
      },
      "source": [
        "# Debugging Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQmCDzgJMjVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.to(\"cpu\")\n",
        "d = iter(tloader)\n",
        "x,y = d.next()\n",
        "#x.to(device)\n",
        "#y.to(device)\n",
        "\n",
        "out= model(x)\n",
        "loss2=criterion(out,y)\n",
        "print(loss2)\n",
        "print(out.shape)\n",
        "print(torch.argmax(out[0], dim=-1))\n",
        "x=x[0,:,:,:]\n",
        "x = x.numpy()\n",
        "plt.imshow(np.transpose(x, (1, 2, 0)))\n",
        "plt.show()\n",
        "\n",
        "#print(torch.argmax(out, dim=1).shape)\n",
        "#out2 = out.detach().numpy()\n",
        "#out3 = np.argmax(out2,axis=1)\n",
        "#out3 = np.squeeze(out3)\n",
        "\n",
        "#print(out2.shape)\n",
        "#print(out3.shape)\n",
        "#print(out3)\n",
        "#print(np.unique(out3))\n",
        "#print(np.unique(y.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhWvPVP6tVqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YVpclnetuK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}